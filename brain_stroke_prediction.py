# -*- coding: utf-8 -*-
"""BRAIN STROKE PREDICTION

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EFXRO_wDvU9yC03VEUxG25rN_mBaSS-0
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data=pd.read_csv("/content/full_filled_stroke_data (1).csv")
data

data.info()

data.describe()

data.isnull()

data.head()

data.columns

import seaborn as sns
sns.countplot(x='stroke',data=data,hue='gender')

data=data.drop(['Residence_type'],axis=1)
data

"""**DATA PROCESSING**

"""

from sklearn.preprocessing import StandardScaler

X_cat = data[['gender', 'hypertension', 'heart_disease', 'ever_married',
       'work_type','smoking_status']]
X_num = data.drop(['gender', 'hypertension', 'heart_disease', 'ever_married',
       'work_type', 'smoking_status', 'stroke'], axis=1)



"""::**get_dummies()-->**gives dummy variables for categorical values."""

X_cat = pd.get_dummies(X_cat)
X_cat

"""**Python sklearn library offers us with StandardScaler() function to standardize the data values into a standard format. Syntax: object = StandardScaler() object. fit_transform(data) According to the above syntax, we initially create an object of the StandardScaler() function**"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_num)
X_scaled = scaler.transform(X_num)
X_scaled = pd.DataFrame(X_scaled, index=X_num.index, columns=X_num.columns)
X = pd.concat([X_scaled, X_cat], axis=1)
y=data['stroke']

X

"""**MODEL BUILDING**

XGBoost Features The library is laser-focused on computational speed and model performance, as such, there are few frills. Model Features Three main forms of gradient boosting are supported:

Gradient Boosting
Stochastic Gradient Boosting
Regularized Gradient Boosting
"""

from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1)

model_xgb = XGBClassifier()
model_xgb.fit(X_train, y_train)

pred = model_xgb.predict(X_test)
print(classification_report(y_test, pred))

fig = plt.figure(figsize=(15,8))
plt.barh(X.columns, model_xgb.feature_importances_)
plt.show()

col=data['ever_married'].value_counts()
col

data.isnull().sum()

data.age.nunique()

for age in data:
  print(data['age'].values)

data['age'].between(13, 75)

fig = plt.figure(figsize=(8,2))
plt.barh(age, model_xgb.feature_importances_)
plt.show()

import seaborn as sns
sns.countplot(x='stroke',data=data,hue='age')

import seaborn as sns
sns.countplot(x='stroke',data=data,hue='hypertension')

import seaborn as sns
sns.countplot(x='stroke',data=data,hue='bmi')

import seaborn as sns
sns.countplot(x='smoking_status',data=data,hue='age')

de=data[(data['age']>58)& (data['smoking_status'])==1]
de

ke=data[(data['smoking_status']==1)]
ke

